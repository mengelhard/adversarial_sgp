{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.contrib import slim\n",
    "from tensorflow.contrib import distributions\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import os\n",
    "\n",
    "from sgp_utils import nlog_fitc, nlog_vfe, fitc_pred, vfe_pred\n",
    "\n",
    "#FLAGS = tf.app.flags.FLAGS\n",
    "#tf.app.flags.DEFINE_string('img_path','./img',\"\"\"Directory for output figs\"\"\")\n",
    "#tf.app.flags.DEFINE_integer('niter',10000,\"\"\"Number of iterations\"\"\")\n",
    "#tf.app.flags.DEFINE_integer('burn_in',100,\"\"\"Head-start for discriminator\"\"\")\n",
    "#tf.app.flags.DEFINE_integer('print_freq',500,\"\"\"How often to display results\"\"\")\n",
    "#tf.app.flags.DEFINE_float('g_lr',2e-5,\"\"\"Generator learning rate\"\"\")\n",
    "#tf.app.flags.DEFINE_float('d_lr',1e-4,\"\"\"Discriminator learning rate\"\"\")\n",
    "#tf.app.flags.DEFINE_integer('batch_size',500,\"\"\"Batch size\"\"\")\n",
    "#tf.app.flags.DEFINE_integer('gen_type',1,\"\"\"Generator Type: 0 for Direct; 1 for Gumbel-softmax\"\"\")\n",
    "#tf.app.flags.DEFINE_string('dataset','kin40k',\"\"\"Dataset to Use\"\"\")\n",
    "#tf.app.flags.DEFINE_float('val_prc',.2,\"\"\"Portion of training data to use for validation\"\"\")\n",
    "#tf.app.flags.DEFINE_integer('n_clusters',100,\"\"\"Number of mixture model clusters\"\"\")\n",
    "#tf.app.flags.DEFINE_integer('n_z',500,\"\"\"Number of pseudo-inputs\"\"\")\n",
    "#tf.app.flags.DEFINE_integer('num_refs',5,\"\"\"Number of (widening) reference distributions\"\"\")\n",
    "\n",
    "## some nonsense to approximate FLAGS in Jupyter\n",
    "\n",
    "class FLAGS:\n",
    "    def __getattr__(self, name):\n",
    "        self.__dict__[name] = FLAGS()\n",
    "        return self.__dict__[name]\n",
    "\n",
    "FLAGS = FLAGS()\n",
    "\n",
    "FLAGS.img_path = './img'\n",
    "FLAGS.niter = 10000\n",
    "FLAGS.burn_in = 100\n",
    "FLAGS.print_freq = 500\n",
    "FLAGS.g_lr = 2e-5\n",
    "FLAGS.d_lr = 1e-4\n",
    "FLAGS.batch_size = 200\n",
    "FLAGS.gen_type = 1\n",
    "FLAGS.dataset = 'kin40k'\n",
    "FLAGS.val_prc = .2\n",
    "FLAGS.n_clusters = 50\n",
    "FLAGS.n_z = 100\n",
    "FLAGS.num_refs = 5\n",
    "FLAGS.num_sgp_samples = 20\n",
    "FLAGS.sgp_approx = 'vfe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kin40k(val_prc=.2):\n",
    "    \n",
    "    import pandas as pd\n",
    "\n",
    "    kin40k_dir = '/Users/mme/Dropbox/_projects/gp_gan/data/kin40k/'\n",
    "\n",
    "    # Read KIN40K Data\n",
    "    train_x = pd.read_csv(kin40k_dir+'kin40k_train_data.asc',sep=' ',header=None,skipinitialspace=True).values\n",
    "    train_y = pd.read_csv(kin40k_dir+'kin40k_train_labels.asc',sep=' ',header=None,skipinitialspace=True).values\n",
    "    test_x = pd.read_csv(kin40k_dir+'kin40k_test_data.asc',sep=' ',header=None,skipinitialspace=True).values\n",
    "    test_y = pd.read_csv(kin40k_dir+'kin40k_test_labels.asc',sep=' ',header=None,skipinitialspace=True).values\n",
    "    train_y = np.squeeze(train_y)\n",
    "    test_y = np.squeeze(test_y)\n",
    "\n",
    "    # Normalize KIN40K Data\n",
    "\n",
    "    x_var = np.var(train_x,axis=0)\n",
    "    x_mean = np.mean(train_x,axis=0)\n",
    "    y_var = np.var(train_y)\n",
    "    y_mean = np.mean(train_y)\n",
    "\n",
    "    train_x = (train_x-x_mean)/x_var\n",
    "    test_x = (test_x-x_mean)/x_var\n",
    "    train_y = (train_y-y_mean)/y_var\n",
    "    test_y = (test_y-y_mean)/y_var\n",
    "\n",
    "    # Create a validation set (20% of training data)\n",
    "\n",
    "    val_indices = np.random.permutation(np.arange(len(train_x)))<int(val_prc*len(train_x))\n",
    "    val_x = train_x[val_indices,:]\n",
    "    val_y = train_y[val_indices]\n",
    "    train_x = train_x[~val_indices,:]\n",
    "    train_y = train_y[~val_indices]\n",
    "\n",
    "    return train_x, train_y, val_x, val_y, test_x, test_y\n",
    "\n",
    "def load_otherdata():\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_mixture_model(d,n_clusters=100,random_state=0):\n",
    "    \"\"\"\n",
    "    Cluster x and return cluster centers and cluster widths (variances)\n",
    "    \"\"\"\n",
    "    from sklearn.cluster import MiniBatchKMeans\n",
    "    km = MiniBatchKMeans(n_clusters=n_clusters,random_state=random_state).fit(d)\n",
    "\n",
    "    lbls = km.labels_\n",
    "    cc = km.cluster_centers_\n",
    "\n",
    "    d_centered = np.array([x - cc[y] for x,y in zip(d,lbls)])\n",
    "    c_widths = np.array([np.sum(d_centered[lbls==c,:]**2,axis=0)/np.sum(lbls==c) \n",
    "        for c in range(n_clusters)])\n",
    "\n",
    "    weights = np.array([np.sum(lbls==c) for c in range(n_clusters)])\n",
    "    weights = weights/np.sum(weights)\n",
    "\n",
    "    mixture_model = {\n",
    "        'n_components':n_clusters,\n",
    "        'n_dims':np.shape(d)[1],\n",
    "        'weights':weights,\n",
    "        'means':cc,\n",
    "        'sds':np.sqrt(c_widths)\n",
    "        }\n",
    "\n",
    "    return mixture_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gumbel-softmax code taken from: \n",
    "# https://github.com/ericjang/gumbel-softmax/blob/master/Categorical%20VAE.ipynb\n",
    "\n",
    "def sample_gumbel(shape, eps=1e-20): \n",
    "    \"\"\"Sample from Gumbel(0, 1)\"\"\"\n",
    "    U = tf.random_uniform(shape,minval=0,maxval=1)\n",
    "    return -tf.log(-tf.log(U + eps) + eps)\n",
    "\n",
    "def gumbel_softmax_sample(logits, temperature): \n",
    "    \"\"\" Draw a sample from the Gumbel-Softmax distribution\"\"\"\n",
    "    y = logits + sample_gumbel(tf.shape(logits))\n",
    "    return tf.nn.softmax(y / temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrelu(x, leak=0.2, name=\"lrelu\"):\n",
    "    return tf.maximum(x, leak*x)\n",
    "\n",
    "def generator_simple(initial_model,tau_initial=.003,reuse=False):\n",
    "    \"\"\"\n",
    "    Use random noise 'eps' to sample from mixture model\n",
    "    \"\"\"\n",
    "    \n",
    "    eps_unif = tf.random_uniform((FLAGS.batch_size,\n",
    "        initial_model['n_components']),dtype=tf.float32)\n",
    "\n",
    "    eps_gauss = tf.random_normal((FLAGS.batch_size,\n",
    "        initial_model['n_dims']),dtype=tf.float32)\n",
    "\n",
    "    with tf.variable_scope(\"generator\", reuse=reuse) as scope:\n",
    "        \n",
    "        means = slim.model_variable('means',\n",
    "                                    shape=np.shape(initial_model['means']),\n",
    "                                    initializer=tf.constant_initializer(initial_model['means'])\n",
    "                                   )\n",
    "        \n",
    "        sds = slim.model_variable('sds',\n",
    "                                  shape=np.shape(initial_model['sds']),\n",
    "                                  initializer=tf.constant_initializer(initial_model['sds'])\n",
    "                                 )\n",
    "        \n",
    "        w = slim.model_variable('weightlogits',\n",
    "                                shape=(initial_model['n_components']),\n",
    "                                initializer=tf.zeros_initializer()\n",
    "                               )\n",
    "                                      \n",
    "        tau = slim.model_variable('tau',\n",
    "                                  shape=np.shape(tau_initial),\n",
    "                                  initializer=tf.constant_initializer(tau_initial)\n",
    "                                 )\n",
    "        \n",
    "        weights = gumbel_softmax_sample(tf.tile(tf.expand_dims(tf.nn.log_softmax(w),\n",
    "                                                               axis=0),(FLAGS.batch_size,1)),temperature=tau)\n",
    "        \n",
    "        y = tf.reduce_sum(weights[:,:,tf.newaxis] * means[tf.newaxis,:,:], axis=1)\n",
    "        y += tf.reduce_sum(weights[:,:,tf.newaxis] * sds[tf.newaxis,:,:],axis=1) * eps_gauss\n",
    "        \n",
    "        return y, w, tau\n",
    "\n",
    "def generator_direct(tau=.003,n_layers=3,reuse=False):\n",
    "    \"\"\"\n",
    "    Use random noise 'eps' to sample from mixture model\n",
    "    \"\"\"\n",
    "\n",
    "    eps_unif = tf.random_uniform((FLAGS.batch_size,\n",
    "        initial_model['n_components']),dtype=tf.float32)\n",
    "\n",
    "    eps_gauss = tf.random_normal((FLAGS.batch_size,\n",
    "        initial_model['n_dims'],\n",
    "        FLAGS.n_z),dtype=tf.float32)\n",
    "\n",
    "    with tf.variable_scope(\"generator\", reuse=reuse) as scope:\n",
    "        \n",
    "        means = slim.model_variable('means',\n",
    "                                    shape=np.shape(initial_model['means']),\n",
    "                                    initializer=tf.constant_initializer(initial_model['means'])\n",
    "                                   )\n",
    "        \n",
    "        sds = slim.model_variable('sds',\n",
    "                                  shape=np.shape(initial_model['sds']),\n",
    "                                  initializer=tf.constant_initializer(initial_model['sds'])\n",
    "                                 )\n",
    "        \n",
    "        slim.stack(eps_unif, slim.fully_connected, \n",
    "                   [100,100,100,initial_model['n_components']], \n",
    "                   activation_fn=tf.nn.elu, \n",
    "                   scope='fc'\n",
    "                  )\n",
    "        \n",
    "        weights = slim.softmax(eps_unif/tau)\n",
    "        \n",
    "        y = tf.reduce_sum(weights[:,:,tf.newaxis] * means[tf.newaxis,:,:], axis=1)\n",
    "        y += tf.reduce_sum(weights[:,:,tf.newaxis] * sds[tf.newaxis,:,:],axis=1) * eps_gauss\n",
    "        \n",
    "        return y, weights\n",
    "\n",
    "def generator_gumbel(initial_model,tau_initial=1e-5,reuse=False):\n",
    "    \"\"\"\n",
    "    Use random noise 'eps' to sample from gumbel softmax, then sample mixture\n",
    "    \"\"\"\n",
    "\n",
    "    eps_unif = tf.random_uniform((FLAGS.batch_size,\n",
    "        initial_model['n_components']),dtype=tf.float32)\n",
    "    \n",
    "    # switch this to do less?\n",
    "    #eps_unif = tf.tile(tf.random_uniform(initial_model['n_components'],dtype=tf.float32)[tf.newaxis,:],\n",
    "    #    batch_size,[batch_size,1])\n",
    "\n",
    "    eps_gauss = tf.random_normal((FLAGS.batch_size,\n",
    "        initial_model['n_dims']),dtype=tf.float32)\n",
    "\n",
    "    with tf.variable_scope(\"generator\", reuse=reuse) as scope:\n",
    "\n",
    "        #tau = slim.model_variable('tau',\n",
    "        #    shape=np.shape(tau_initial),\n",
    "        #    initializer=tf.constant_initializer(tau_initial)\n",
    "        #    )\n",
    "        \n",
    "        #for now, let's try fixed tau\n",
    "        \n",
    "        tau = tau_initial\n",
    "        \n",
    "        means = slim.model_variable('means',\n",
    "            shape=np.shape(initial_model['means']),\n",
    "            initializer=tf.constant_initializer(initial_model['means'])\n",
    "            )\n",
    "        \n",
    "        sds = slim.model_variable('sds',\n",
    "            shape=np.shape(initial_model['sds']),\n",
    "            initializer=tf.constant_initializer(initial_model['sds'])\n",
    "            )\n",
    "        \n",
    "        with slim.arg_scope([slim.fully_connected], activation_fn=lrelu):\n",
    "            net = slim.fully_connected(eps_unif, 256, scope='fc_0')\n",
    "            \n",
    "            for i in range(5):\n",
    "                dnet = slim.fully_connected(net, 256, scope='fc_%d_r0' % (i+1))\n",
    "                net += slim.fully_connected(dnet, 256, activation_fn=None, scope='fc_%d_r1' % (i+1),\n",
    "                    weights_initializer=tf.constant_initializer(0.))\n",
    "                net = lrelu(net)\n",
    "\n",
    "        T = slim.fully_connected(net, initial_model['n_components'], activation_fn=None, scope='T',\n",
    "            weights_initializer=tf.constant_initializer(0.))\n",
    "\n",
    "        #weights = tf.nn.softmax((tf.nn.log_softmax(T,axis=1) + gumbel)/tau,axis=1)\n",
    "\n",
    "        weights = gumbel_softmax_sample(tf.nn.log_softmax(T,axis=1),temperature=tau)\n",
    "                \n",
    "        # dimension should be: (batch_size, n_components, dimension)\n",
    "        y = tf.reduce_sum(weights[:,:,tf.newaxis] * means[tf.newaxis,:,:], axis=1)\n",
    "        y += tf.reduce_sum(weights[:,:,tf.newaxis] * sds[tf.newaxis,:,:],axis=1) * eps_gauss\n",
    "                \n",
    "        return y, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversary(y, reuse=False):\n",
    "    with tf.variable_scope(\"adversary\", reuse=reuse) as scope:\n",
    "        with slim.arg_scope([slim.fully_connected], activation_fn=lrelu):\n",
    "            net = slim.fully_connected(y, 256, scope='fc_0')\n",
    "\n",
    "            for i in range(5):\n",
    "                dnet = slim.fully_connected(net, 256, scope='fc_%d_r0' % (i+1))\n",
    "                net += slim.fully_connected(dnet, 256, activation_fn=None, scope='fc_%d_r1' % (i+1),\n",
    "                                            weights_initializer=tf.constant_initializer(0.))\n",
    "                net = lrelu(net) \n",
    "\n",
    "        T = slim.fully_connected(net, 1, activation_fn=None, scope='T',\n",
    "                                weights_initializer=tf.constant_initializer(0.))\n",
    "        T = tf.squeeze(T, [1])\n",
    "        return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reference(d, num_refs=FLAGS.num_refs):\n",
    "    \n",
    "    mmref = kmeans_mixture_model(d,n_clusters=1)\n",
    "    \n",
    "    ref = distributions.MixtureSameFamily(\n",
    "        mixture_distribution=distributions.Categorical(\n",
    "            probs=[.2]*num_refs),\n",
    "        components_distribution=distributions.MultivariateNormalDiag(\n",
    "            loc=np.array([mmref['means'][0]]*num_refs).astype(np.float32),\n",
    "            scale_diag=np.array([mmref['sds'][0]*scale for scale in [2**e for e in range(num_refs)]]).astype(\n",
    "                np.float32)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return ref.log_prob, ref.sample\n",
    "\n",
    "#reflogprob, rs = reference(t_x, num_refs = FLAGS.num_refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logdet(matrix):\n",
    "    chol = tf.cholesky(matrix)\n",
    "    return 2.0 * tf.reduce_sum(tf.log(tf.real(tf.matrix_diag_part(chol))),reduction_indices=[-1])\n",
    "\n",
    "def pairwise_distance(x1,x2):\n",
    "    r1 = tf.reduce_sum(x1**2,axis=2)[:,:,tf.newaxis]\n",
    "    r2 = tf.reduce_sum(x2**2,axis=2)[:,tf.newaxis,:]\n",
    "    r12 = tf.matmul(x1,tf.matrix_transpose(x2))\n",
    "    return r1+r2-2*r12\n",
    "\n",
    "def nlog_vfe(x,y,m,sls,sfs,noise):\n",
    "\n",
    "    P = tf.shape(m)[0] # number of pseudo-input samples\n",
    "    y = tf.tile(tf.expand_dims(tf.cast(y,dtype=tf.float32),0),(P,1))\n",
    "    x = tf.tile(tf.expand_dims(tf.cast(x,dtype=tf.float32),0),(P,1,1))\n",
    "\n",
    "    D = tf.shape(x)[2]\n",
    "    X = tf.shape(x)[1]\n",
    "\n",
    "    logtp = tf.constant(np.log(2.*np.pi),dtype=tf.float32)\n",
    "\n",
    "    #m = m + 1e-6*tf.random_normal(tf.shape(m),dtype=tf.float32)\n",
    "\n",
    "    M = tf.shape(m)[1]\n",
    "\n",
    "    jitter = 1e-6*tf.eye(M,dtype=tf.float32)[tf.newaxis,:,:]\n",
    "\n",
    "    xm = pairwise_distance(x,m)\n",
    "    mm = pairwise_distance(m,m)\n",
    "\n",
    "    kxm = sfs[:,tf.newaxis,tf.newaxis]*tf.exp(-.5*xm/sls[:,tf.newaxis,tf.newaxis])\n",
    "    kmm = sfs[:,tf.newaxis,tf.newaxis]*tf.exp(-.5*mm/sls[:,tf.newaxis,tf.newaxis])\n",
    "    \n",
    "    kmx = tf.matrix_transpose(kxm)\n",
    "    kmmi = tf.matrix_inverse(kmm+jitter)\n",
    "\n",
    "    qmm_diag = tf.reduce_sum(tf.matmul(kxm,kmmi)*kxm,axis=2)\n",
    "    \n",
    "    gd = noise[:,tf.newaxis]\n",
    "    gid = 1/gd\n",
    "\n",
    "    tr = sfs*tf.cast(X,tf.float32)-tf.reduce_sum(qmm_diag,axis=1)\n",
    "    \n",
    "    kmx_gi_kxm = tf.matmul(kmx,kxm)/noise[:,tf.newaxis,tf.newaxis]\n",
    "\n",
    "    giy = gid*y\n",
    "    kgiy = tf.reduce_sum(kmx*giy[:,tf.newaxis,:],axis=2)\n",
    "\n",
    "    inner = kmmi+kmx_gi_kxm+jitter\n",
    "\n",
    "    covd = logdet(inner)+logdet(kmm+jitter)+tf.log(noise)*tf.cast(X,dtype=tf.float32)\n",
    "    \n",
    "    t1 = .5*tf.cast(X,tf.float32)*logtp\n",
    "    t2 = .5*tf.reduce_sum(y*y*gid,axis=1) - .5*tf.reduce_sum(\n",
    "        tf.reduce_sum(kgiy[:,:,tf.newaxis]*tf.matrix_inverse(inner),axis=1)*kgiy,axis=1)\n",
    "    t3 = .5*covd\n",
    "    t4 = .5*tf.div(tr,noise)\n",
    "    \n",
    "    return t1+t2+t3+t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_samples(x,rows_per_sample,n_samples,axis=0):\n",
    "    indices = tf.random_uniform((n_samples,tf.shape(x)[0]),dtype=tf.float32)\n",
    "    _, indices = tf.nn.top_k(indices,k=rows_per_sample)\n",
    "    return tf.gather(x,indices), indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-9c5a671417bc>:11: MultivariateNormalDiag.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_diag) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /Users/mme/anaconda/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_diag.py:224: MultivariateNormalLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /Users/mme/anaconda/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_linear_operator.py:201: AffineLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.bijectors.affine_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /Users/mme/anaconda/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/bijectors/affine_linear_operator.py:158: _DistributionShape.__init__ (from tensorflow.contrib.distributions.python.ops.shape) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From <ipython-input-7-9c5a671417bc>:11: MixtureSameFamily.__init__ (from tensorflow.contrib.distributions.python.ops.mixture_same_family) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n"
     ]
    }
   ],
   "source": [
    "### MAIN ###\n",
    "\n",
    "# Load data\n",
    "\n",
    "if FLAGS.dataset == 'kin40k':\n",
    "    train_x, train_y, val_x, val_y, test_x, test_y = load_kin40k(val_prc=FLAGS.val_prc)\n",
    "\n",
    "# PSEUDOCODE HERE FOR THE MOMENT\n",
    "\n",
    "initial_model = kmeans_mixture_model(train_x,n_clusters=FLAGS.n_clusters)\n",
    "\n",
    "# specify the generator that will learn this mixture model\n",
    "\n",
    "if FLAGS.gen_type == 1:\n",
    "    y, weights, tau = generator_simple(initial_model)\n",
    "    #y, weights = generator_gumbel(initial_model)\n",
    "else:\n",
    "    y, weights = generator_direct(initial_model)\n",
    "\n",
    "# specify the reference distribution. we need to both evaluate and sample\n",
    "\n",
    "reflogprob, rs = reference(train_x, num_refs = FLAGS.num_refs)\n",
    "refsample = tf.cast(rs(sample_shape=FLAGS.batch_size),dtype=tf.float32)\n",
    "\n",
    "# specify the adversary, which will learn the likelihood ratio\n",
    "# between generator samples and reference samples\n",
    "\n",
    "dref = adversary(refsample)\n",
    "dy = adversary(y,reuse=True)\n",
    "\n",
    "# temporary assignment of kernel hyperparams using Inverse Gamma\n",
    "#sls = distributions.InverseGamma(concentration=1., rate=1.).sample(sample_shape=FLAGS.num_sgp_samples)\n",
    "#sfs = distributions.InverseGamma(concentration=1., rate=1.).sample(sample_shape=FLAGS.num_sgp_samples)\n",
    "#noise = distributions.InverseGamma(concentration=1., rate=1.).sample(sample_shape=FLAGS.num_sgp_samples)\n",
    "\n",
    "sls = tf.constant([1.]*FLAGS.num_sgp_samples,dtype=tf.float32)\n",
    "sfs = tf.constant([1.]*FLAGS.num_sgp_samples,dtype=tf.float32)\n",
    "noise = tf.constant([.1]*FLAGS.num_sgp_samples,dtype=tf.float32)\n",
    "\n",
    "# Get SGP stuff\n",
    "z, z_idx = random_samples(y,FLAGS.n_z,FLAGS.num_sgp_samples) # samples of (full sets of) pseudo-inputs\n",
    "sgp_nlogprob = nlog_vfe(train_x,train_y,z,sls,sfs,noise)\n",
    "ref_logprob = tf.reduce_sum(reflogprob(z),axis=1)\n",
    "dz = tf.reduce_sum(tf.gather(dy,z_idx),axis=1)\n",
    "    \n",
    "# prepare for run\n",
    "\n",
    "dvars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"adversary\")\n",
    "gvars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"generator\")\n",
    "\n",
    "dloss = tf.reduce_mean(\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(logits=dy, labels=tf.ones_like(dy))\n",
    "    + tf.nn.sigmoid_cross_entropy_with_logits(logits=dref, labels=tf.zeros_like(dref))\n",
    ")\n",
    "\n",
    "gloss = tf.reduce_sum(ref_logprob + sgp_nlogprob + dz, axis=0)\n",
    "\n",
    "dtrain_step = tf.train.AdamOptimizer(FLAGS.d_lr).minimize(dloss,var_list=dvars)\n",
    "gtrain_step = tf.train.AdamOptimizer(FLAGS.g_lr).minimize(gloss,var_list=gvars)\n",
    "\n",
    "outdir = FLAGS.img_path\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(sess, niter=FLAGS.niter, ninitial=FLAGS.burn_in, figdir=FLAGS.img_path):\n",
    "\n",
    "    # consider a burn-in period for the discriminator before going to the generator\n",
    "\n",
    "    burn_in = tqdm_notebook(range(ninitial))\n",
    "\n",
    "    for i in burn_in:\n",
    "\n",
    "        y_,weights_,tau_,refsample_,dref_,dy_,dloss_,_ = sess.run([y,weights,tau,refsample,dref,dy,dloss,dtrain_step])\n",
    "\n",
    "        burn_in.set_description(\"dloss=%.3f\"  % (dloss_))\n",
    "\n",
    "    progress = tqdm_notebook(range(niter))\n",
    "\n",
    "    for i in progress:\n",
    "\n",
    "        y_,weights_,refsample_,dref_,dy_,dloss_,_ = sess.run([y,weights,refsample,dref,dy,dloss,dtrain_step])\n",
    "        gloss_, _ = sess.run([gloss,gtrain_step])\n",
    "\n",
    "        #print(np.shape(y_),np.shape(refsample_))\n",
    "\n",
    "        progress.set_description(\"dloss=%.3f, gloss=%.3f\"  % (dloss_,gloss_))\n",
    "        \n",
    "        if i%10 == 0:\n",
    "            #unique, counts = np.unique(weights_, return_counts=True)\n",
    "            #print(np.array((unique, counts)).T)\n",
    "            #print(tau_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2617118219494da1b5899691b4b5cc4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c35779f3e54cc6aba65b99833a341c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. 50.]]\n",
      "0.003\n",
      "[[-1.04187100e-04  1.00000000e+00]\n",
      " [-9.16260178e-05  1.00000000e+00]\n",
      " [-8.66371993e-05  1.00000000e+00]\n",
      " [-8.37518091e-05  1.00000000e+00]\n",
      " [-8.07654142e-05  1.00000000e+00]\n",
      " [-7.65696968e-05  1.00000000e+00]\n",
      " [-7.56021764e-05  1.00000000e+00]\n",
      " [-7.44973586e-05  1.00000000e+00]\n",
      " [-7.43167184e-05  1.00000000e+00]\n",
      " [-7.36162110e-05  1.00000000e+00]\n",
      " [-7.33930938e-05  1.00000000e+00]\n",
      " [-7.21911128e-05  1.00000000e+00]\n",
      " [-7.20259341e-05  1.00000000e+00]\n",
      " [-6.77150601e-05  1.00000000e+00]\n",
      " [-5.46998999e-05  1.00000000e+00]\n",
      " [-5.40253823e-05  1.00000000e+00]\n",
      " [-5.39434332e-05  1.00000000e+00]\n",
      " [-5.10986465e-05  1.00000000e+00]\n",
      " [-5.05556745e-05  1.00000000e+00]\n",
      " [-4.83980439e-05  1.00000000e+00]\n",
      " [-4.18237287e-05  1.00000000e+00]\n",
      " [-3.12371667e-05  1.00000000e+00]\n",
      " [-2.81949542e-05  1.00000000e+00]\n",
      " [-2.80933600e-05  1.00000000e+00]\n",
      " [-2.36414180e-05  1.00000000e+00]\n",
      " [-8.31566285e-06  1.00000000e+00]\n",
      " [-2.84359521e-06  1.00000000e+00]\n",
      " [ 1.02606054e-06  1.00000000e+00]\n",
      " [ 3.24930261e-06  1.00000000e+00]\n",
      " [ 5.38318818e-06  1.00000000e+00]\n",
      " [ 6.36346294e-06  1.00000000e+00]\n",
      " [ 1.40498632e-05  1.00000000e+00]\n",
      " [ 2.53722337e-05  1.00000000e+00]\n",
      " [ 2.77612344e-05  1.00000000e+00]\n",
      " [ 3.28193128e-05  1.00000000e+00]\n",
      " [ 3.70648886e-05  1.00000000e+00]\n",
      " [ 4.25790822e-05  1.00000000e+00]\n",
      " [ 4.53074972e-05  1.00000000e+00]\n",
      " [ 4.60666633e-05  1.00000000e+00]\n",
      " [ 5.05328353e-05  1.00000000e+00]\n",
      " [ 5.13585655e-05  1.00000000e+00]\n",
      " [ 5.18408560e-05  1.00000000e+00]\n",
      " [ 5.18462439e-05  1.00000000e+00]\n",
      " [ 6.05496716e-05  1.00000000e+00]\n",
      " [ 7.04010599e-05  1.00000000e+00]\n",
      " [ 7.33267589e-05  1.00000000e+00]\n",
      " [ 8.98494036e-05  1.00000000e+00]\n",
      " [ 1.00162506e-04  1.00000000e+00]\n",
      " [ 1.06038184e-04  1.00000000e+00]\n",
      " [ 1.10279027e-04  1.00000000e+00]]\n",
      "0.003\n",
      "[[-1.58022245e-04  1.00000000e+00]\n",
      " [-1.48073203e-04  1.00000000e+00]\n",
      " [-1.44756646e-04  1.00000000e+00]\n",
      " [-1.40640055e-04  1.00000000e+00]\n",
      " [-1.38409276e-04  1.00000000e+00]\n",
      " [-1.27193867e-04  1.00000000e+00]\n",
      " [-1.20520926e-04  1.00000000e+00]\n",
      " [-1.07559652e-04  1.00000000e+00]\n",
      " [-1.07547668e-04  1.00000000e+00]\n",
      " [-1.07404900e-04  1.00000000e+00]\n",
      " [-1.06936364e-04  1.00000000e+00]\n",
      " [-9.97775496e-05  1.00000000e+00]\n",
      " [-9.66273874e-05  1.00000000e+00]\n",
      " [-8.86944399e-05  1.00000000e+00]\n",
      " [-8.54939717e-05  1.00000000e+00]\n",
      " [-8.18445260e-05  1.00000000e+00]\n",
      " [-8.14583836e-05  1.00000000e+00]\n",
      " [-6.74729163e-05  1.00000000e+00]\n",
      " [-5.58657048e-05  1.00000000e+00]\n",
      " [-5.32022023e-05  1.00000000e+00]\n",
      " [-5.29290664e-05  1.00000000e+00]\n",
      " [-4.74815788e-05  1.00000000e+00]\n",
      " [-3.42557614e-05  1.00000000e+00]\n",
      " [-3.24345820e-05  1.00000000e+00]\n",
      " [-2.60948182e-05  1.00000000e+00]\n",
      " [-1.59278188e-05  1.00000000e+00]\n",
      " [-1.06149382e-05  1.00000000e+00]\n",
      " [ 1.25308761e-05  1.00000000e+00]\n",
      " [ 1.74929046e-05  1.00000000e+00]\n",
      " [ 2.19977774e-05  1.00000000e+00]\n",
      " [ 2.61605546e-05  1.00000000e+00]\n",
      " [ 3.27995767e-05  1.00000000e+00]\n",
      " [ 4.12345253e-05  1.00000000e+00]\n",
      " [ 4.71378808e-05  1.00000000e+00]\n",
      " [ 5.51009871e-05  1.00000000e+00]\n",
      " [ 6.26669498e-05  1.00000000e+00]\n",
      " [ 6.36272380e-05  1.00000000e+00]\n",
      " [ 6.90692104e-05  1.00000000e+00]\n",
      " [ 7.84220611e-05  1.00000000e+00]\n",
      " [ 8.19932320e-05  1.00000000e+00]\n",
      " [ 8.64687099e-05  1.00000000e+00]\n",
      " [ 8.67989947e-05  1.00000000e+00]\n",
      " [ 9.05102133e-05  1.00000000e+00]\n",
      " [ 1.05982122e-04  1.00000000e+00]\n",
      " [ 1.17775569e-04  1.00000000e+00]\n",
      " [ 1.26693965e-04  1.00000000e+00]\n",
      " [ 1.34727990e-04  1.00000000e+00]\n",
      " [ 1.42675330e-04  1.00000000e+00]\n",
      " [ 1.65857709e-04  1.00000000e+00]\n",
      " [ 1.66687896e-04  1.00000000e+00]]\n",
      "0.003\n",
      "[[-1.86608289e-04  1.00000000e+00]\n",
      " [-1.83862256e-04  1.00000000e+00]\n",
      " [-1.76314192e-04  1.00000000e+00]\n",
      " [-1.64959521e-04  1.00000000e+00]\n",
      " [-1.64630328e-04  1.00000000e+00]\n",
      " [-1.60961630e-04  1.00000000e+00]\n",
      " [-1.41134908e-04  1.00000000e+00]\n",
      " [-1.38751362e-04  1.00000000e+00]\n",
      " [-1.35128226e-04  1.00000000e+00]\n",
      " [-1.31268258e-04  1.00000000e+00]\n",
      " [-1.19414646e-04  1.00000000e+00]\n",
      " [-1.12954520e-04  1.00000000e+00]\n",
      " [-1.03390230e-04  1.00000000e+00]\n",
      " [-9.57227385e-05  1.00000000e+00]\n",
      " [-9.52842747e-05  1.00000000e+00]\n",
      " [-8.18398839e-05  1.00000000e+00]\n",
      " [-7.64197903e-05  1.00000000e+00]\n",
      " [-6.57293567e-05  1.00000000e+00]\n",
      " [-6.11676005e-05  1.00000000e+00]\n",
      " [-5.94479789e-05  1.00000000e+00]\n",
      " [-5.55693441e-05  1.00000000e+00]\n",
      " [-4.41486191e-05  1.00000000e+00]\n",
      " [-4.30137625e-05  1.00000000e+00]\n",
      " [-3.44350919e-05  1.00000000e+00]\n",
      " [-2.32887360e-05  1.00000000e+00]\n",
      " [-1.76845697e-05  1.00000000e+00]\n",
      " [-6.85045779e-06  1.00000000e+00]\n",
      " [-6.08413620e-06  1.00000000e+00]\n",
      " [ 3.58676289e-06  1.00000000e+00]\n",
      " [ 4.41498341e-05  1.00000000e+00]\n",
      " [ 5.13258456e-05  1.00000000e+00]\n",
      " [ 5.51995799e-05  1.00000000e+00]\n",
      " [ 6.23418382e-05  1.00000000e+00]\n",
      " [ 6.58116260e-05  1.00000000e+00]\n",
      " [ 6.71544694e-05  1.00000000e+00]\n",
      " [ 7.02810139e-05  1.00000000e+00]\n",
      " [ 7.18540905e-05  1.00000000e+00]\n",
      " [ 9.32157782e-05  1.00000000e+00]\n",
      " [ 9.34777199e-05  1.00000000e+00]\n",
      " [ 9.88454121e-05  1.00000000e+00]\n",
      " [ 1.06654872e-04  1.00000000e+00]\n",
      " [ 1.08772037e-04  1.00000000e+00]\n",
      " [ 1.08792803e-04  1.00000000e+00]\n",
      " [ 1.10151756e-04  1.00000000e+00]\n",
      " [ 1.41215423e-04  1.00000000e+00]\n",
      " [ 1.61027783e-04  1.00000000e+00]\n",
      " [ 1.80787290e-04  1.00000000e+00]\n",
      " [ 1.88314763e-04  1.00000000e+00]\n",
      " [ 2.12170271e-04  1.00000000e+00]\n",
      " [ 2.17180146e-04  1.00000000e+00]]\n",
      "0.003\n",
      "[[-2.31327533e-04  1.00000000e+00]\n",
      " [-2.16123270e-04  1.00000000e+00]\n",
      " [-2.09288570e-04  1.00000000e+00]\n",
      " [-2.03253090e-04  1.00000000e+00]\n",
      " [-1.98752372e-04  1.00000000e+00]\n",
      " [-1.95752567e-04  1.00000000e+00]\n",
      " [-1.86338802e-04  1.00000000e+00]\n",
      " [-1.77908747e-04  1.00000000e+00]\n",
      " [-1.69175910e-04  1.00000000e+00]\n",
      " [-1.44049191e-04  1.00000000e+00]\n",
      " [-1.29572378e-04  1.00000000e+00]\n",
      " [-1.11864108e-04  1.00000000e+00]\n",
      " [-1.03680533e-04  1.00000000e+00]\n",
      " [-1.01334139e-04  1.00000000e+00]\n",
      " [-9.94227012e-05  1.00000000e+00]\n",
      " [-9.56069271e-05  1.00000000e+00]\n",
      " [-8.27847543e-05  1.00000000e+00]\n",
      " [-5.48353382e-05  1.00000000e+00]\n",
      " [-4.80466260e-05  1.00000000e+00]\n",
      " [-4.49754261e-05  1.00000000e+00]\n",
      " [-4.44645921e-05  1.00000000e+00]\n",
      " [-3.98343363e-05  1.00000000e+00]\n",
      " [-3.93513546e-05  1.00000000e+00]\n",
      " [-3.33495809e-05  1.00000000e+00]\n",
      " [-3.04655750e-05  1.00000000e+00]\n",
      " [-1.88951853e-05  1.00000000e+00]\n",
      " [-1.08939130e-05  1.00000000e+00]\n",
      " [-1.04588653e-05  1.00000000e+00]\n",
      " [-2.94043070e-06  1.00000000e+00]\n",
      " [ 1.32771356e-06  1.00000000e+00]\n",
      " [ 1.78822154e-06  1.00000000e+00]\n",
      " [ 7.26609578e-05  1.00000000e+00]\n",
      " [ 7.32837434e-05  1.00000000e+00]\n",
      " [ 7.96625609e-05  1.00000000e+00]\n",
      " [ 8.17769105e-05  1.00000000e+00]\n",
      " [ 8.78723949e-05  1.00000000e+00]\n",
      " [ 8.88320355e-05  1.00000000e+00]\n",
      " [ 9.22703912e-05  1.00000000e+00]\n",
      " [ 9.90590052e-05  1.00000000e+00]\n",
      " [ 1.00049052e-04  1.00000000e+00]\n",
      " [ 1.00917518e-04  1.00000000e+00]\n",
      " [ 1.06496875e-04  1.00000000e+00]\n",
      " [ 1.17571049e-04  1.00000000e+00]\n",
      " [ 1.49462838e-04  1.00000000e+00]\n",
      " [ 1.75401932e-04  1.00000000e+00]\n",
      " [ 1.82512435e-04  1.00000000e+00]\n",
      " [ 1.99581802e-04  1.00000000e+00]\n",
      " [ 2.23503186e-04  1.00000000e+00]\n",
      " [ 2.38855064e-04  1.00000000e+00]\n",
      " [ 2.45694275e-04  1.00000000e+00]]\n",
      "0.003\n",
      "[[-2.90729949e-04  1.00000000e+00]\n",
      " [-2.72441219e-04  1.00000000e+00]\n",
      " [-2.59722088e-04  1.00000000e+00]\n",
      " [-2.47392134e-04  1.00000000e+00]\n",
      " [-2.37135231e-04  1.00000000e+00]\n",
      " [-2.11410108e-04  1.00000000e+00]\n",
      " [-1.96043067e-04  1.00000000e+00]\n",
      " [-1.92248714e-04  1.00000000e+00]\n",
      " [-1.74827233e-04  1.00000000e+00]\n",
      " [-1.70980697e-04  1.00000000e+00]\n",
      " [-1.64270241e-04  1.00000000e+00]\n",
      " [-1.39533964e-04  1.00000000e+00]\n",
      " [-1.21392237e-04  1.00000000e+00]\n",
      " [-1.13135728e-04  1.00000000e+00]\n",
      " [-1.06330517e-04  1.00000000e+00]\n",
      " [-1.02227918e-04  1.00000000e+00]\n",
      " [-7.83520591e-05  1.00000000e+00]\n",
      " [-7.79289403e-05  1.00000000e+00]\n",
      " [-6.44413230e-05  1.00000000e+00]\n",
      " [-4.66838937e-05  1.00000000e+00]\n",
      " [-4.54623332e-05  1.00000000e+00]\n",
      " [-4.04310085e-05  1.00000000e+00]\n",
      " [-3.70790367e-05  1.00000000e+00]\n",
      " [-2.93222802e-05  1.00000000e+00]\n",
      " [-1.93725973e-05  1.00000000e+00]\n",
      " [-1.43738789e-05  1.00000000e+00]\n",
      " [-8.03797320e-06  1.00000000e+00]\n",
      " [ 2.39983774e-06  1.00000000e+00]\n",
      " [ 2.16310982e-05  1.00000000e+00]\n",
      " [ 2.53621711e-05  1.00000000e+00]\n",
      " [ 3.62581341e-05  1.00000000e+00]\n",
      " [ 5.67639290e-05  1.00000000e+00]\n",
      " [ 5.72528661e-05  1.00000000e+00]\n",
      " [ 5.76231687e-05  1.00000000e+00]\n",
      " [ 7.78921967e-05  1.00000000e+00]\n",
      " [ 7.99766349e-05  1.00000000e+00]\n",
      " [ 8.05516684e-05  1.00000000e+00]\n",
      " [ 8.99435108e-05  1.00000000e+00]\n",
      " [ 9.96827366e-05  1.00000000e+00]\n",
      " [ 1.04496881e-04  1.00000000e+00]\n",
      " [ 1.21008095e-04  1.00000000e+00]\n",
      " [ 1.32175512e-04  1.00000000e+00]\n",
      " [ 1.47329425e-04  1.00000000e+00]\n",
      " [ 1.64217359e-04  1.00000000e+00]\n",
      " [ 2.06024037e-04  1.00000000e+00]\n",
      " [ 2.13144289e-04  1.00000000e+00]\n",
      " [ 2.40840018e-04  1.00000000e+00]\n",
      " [ 2.41930553e-04  1.00000000e+00]\n",
      " [ 2.49396951e-04  1.00000000e+00]\n",
      " [ 2.88621348e-04  1.00000000e+00]]\n",
      "0.003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.51448689e-04  1.00000000e+00]\n",
      " [-2.95320933e-04  1.00000000e+00]\n",
      " [-2.88165116e-04  1.00000000e+00]\n",
      " [-2.87940464e-04  1.00000000e+00]\n",
      " [-2.78592226e-04  1.00000000e+00]\n",
      " [-2.63042137e-04  1.00000000e+00]\n",
      " [-2.22077360e-04  1.00000000e+00]\n",
      " [-2.15295411e-04  1.00000000e+00]\n",
      " [-2.08824393e-04  1.00000000e+00]\n",
      " [-1.78791277e-04  1.00000000e+00]\n",
      " [-1.76063593e-04  1.00000000e+00]\n",
      " [-1.42353223e-04  1.00000000e+00]\n",
      " [-1.16562362e-04  1.00000000e+00]\n",
      " [-1.08531654e-04  1.00000000e+00]\n",
      " [-1.02810780e-04  1.00000000e+00]\n",
      " [-1.02470403e-04  1.00000000e+00]\n",
      " [-8.35078972e-05  1.00000000e+00]\n",
      " [-7.78491521e-05  1.00000000e+00]\n",
      " [-6.79749865e-05  1.00000000e+00]\n",
      " [-5.68749965e-05  1.00000000e+00]\n",
      " [-5.27614975e-05  1.00000000e+00]\n",
      " [-4.06089457e-05  1.00000000e+00]\n",
      " [-3.34898104e-05  1.00000000e+00]\n",
      " [-1.72346736e-05  1.00000000e+00]\n",
      " [-1.05337740e-05  1.00000000e+00]\n",
      " [-4.95519771e-06  1.00000000e+00]\n",
      " [-1.03155685e-06  1.00000000e+00]\n",
      " [ 4.52092308e-06  1.00000000e+00]\n",
      " [ 9.69451048e-06  1.00000000e+00]\n",
      " [ 1.29978598e-05  1.00000000e+00]\n",
      " [ 2.64189348e-05  1.00000000e+00]\n",
      " [ 5.21203692e-05  1.00000000e+00]\n",
      " [ 5.99659288e-05  1.00000000e+00]\n",
      " [ 7.64051292e-05  1.00000000e+00]\n",
      " [ 8.46775729e-05  1.00000000e+00]\n",
      " [ 8.73239624e-05  1.00000000e+00]\n",
      " [ 8.82351742e-05  1.00000000e+00]\n",
      " [ 9.18733422e-05  1.00000000e+00]\n",
      " [ 1.19600911e-04  1.00000000e+00]\n",
      " [ 1.22641140e-04  1.00000000e+00]\n",
      " [ 1.32082321e-04  1.00000000e+00]\n",
      " [ 1.45661106e-04  1.00000000e+00]\n",
      " [ 1.67587874e-04  1.00000000e+00]\n",
      " [ 1.90092876e-04  1.00000000e+00]\n",
      " [ 2.08539583e-04  1.00000000e+00]\n",
      " [ 2.17802924e-04  1.00000000e+00]\n",
      " [ 2.27462791e-04  1.00000000e+00]\n",
      " [ 2.53634033e-04  1.00000000e+00]\n",
      " [ 2.80065113e-04  1.00000000e+00]\n",
      " [ 3.31830670e-04  1.00000000e+00]]\n",
      "0.003\n",
      "[[-3.89960042e-04  1.00000000e+00]\n",
      " [-3.59072932e-04  1.00000000e+00]\n",
      " [-2.88834766e-04  1.00000000e+00]\n",
      " [-2.73063924e-04  1.00000000e+00]\n",
      " [-2.57760083e-04  1.00000000e+00]\n",
      " [-2.55825376e-04  1.00000000e+00]\n",
      " [-2.48407567e-04  1.00000000e+00]\n",
      " [-2.40347756e-04  1.00000000e+00]\n",
      " [-2.37951928e-04  1.00000000e+00]\n",
      " [-1.94208333e-04  1.00000000e+00]\n",
      " [-1.91241241e-04  1.00000000e+00]\n",
      " [-1.66219310e-04  1.00000000e+00]\n",
      " [-1.45973492e-04  1.00000000e+00]\n",
      " [-1.45473299e-04  1.00000000e+00]\n",
      " [-1.18194934e-04  1.00000000e+00]\n",
      " [-1.09404209e-04  1.00000000e+00]\n",
      " [-1.08437882e-04  1.00000000e+00]\n",
      " [-1.03643149e-04  1.00000000e+00]\n",
      " [-9.31682662e-05  1.00000000e+00]\n",
      " [-6.95682247e-05  1.00000000e+00]\n",
      " [-3.66592067e-05  1.00000000e+00]\n",
      " [-2.96998223e-05  1.00000000e+00]\n",
      " [-2.32280127e-05  1.00000000e+00]\n",
      " [-1.50742972e-05  1.00000000e+00]\n",
      " [-3.90142759e-06  1.00000000e+00]\n",
      " [ 4.52880749e-06  1.00000000e+00]\n",
      " [ 5.46189176e-06  1.00000000e+00]\n",
      " [ 1.64738958e-05  1.00000000e+00]\n",
      " [ 2.50485973e-05  1.00000000e+00]\n",
      " [ 2.65727285e-05  1.00000000e+00]\n",
      " [ 5.37963570e-05  1.00000000e+00]\n",
      " [ 5.70516349e-05  1.00000000e+00]\n",
      " [ 5.74724909e-05  1.00000000e+00]\n",
      " [ 6.66601627e-05  1.00000000e+00]\n",
      " [ 7.39411116e-05  1.00000000e+00]\n",
      " [ 9.05198031e-05  1.00000000e+00]\n",
      " [ 9.35690769e-05  1.00000000e+00]\n",
      " [ 9.86353843e-05  1.00000000e+00]\n",
      " [ 1.05047693e-04  1.00000000e+00]\n",
      " [ 1.24872546e-04  1.00000000e+00]\n",
      " [ 1.28165251e-04  1.00000000e+00]\n",
      " [ 1.40393793e-04  1.00000000e+00]\n",
      " [ 1.74147121e-04  1.00000000e+00]\n",
      " [ 1.99695787e-04  1.00000000e+00]\n",
      " [ 2.07582692e-04  1.00000000e+00]\n",
      " [ 2.21934839e-04  1.00000000e+00]\n",
      " [ 2.54923565e-04  1.00000000e+00]\n",
      " [ 2.67487660e-04  1.00000000e+00]\n",
      " [ 2.99756357e-04  1.00000000e+00]\n",
      " [ 3.83989565e-04  1.00000000e+00]]\n",
      "0.003\n",
      "[[-3.96990101e-04  1.00000000e+00]\n",
      " [-3.81929451e-04  1.00000000e+00]\n",
      " [-3.37954698e-04  1.00000000e+00]\n",
      " [-2.81273795e-04  1.00000000e+00]\n",
      " [-2.75662751e-04  1.00000000e+00]\n",
      " [-2.46877462e-04  1.00000000e+00]\n",
      " [-2.46326643e-04  1.00000000e+00]\n",
      " [-2.43733564e-04  1.00000000e+00]\n",
      " [-2.09235484e-04  1.00000000e+00]\n",
      " [-2.06127734e-04  1.00000000e+00]\n",
      " [-2.04322743e-04  1.00000000e+00]\n",
      " [-2.03049945e-04  1.00000000e+00]\n",
      " [-1.98087320e-04  1.00000000e+00]\n",
      " [-1.96110152e-04  1.00000000e+00]\n",
      " [-1.20014476e-04  1.00000000e+00]\n",
      " [-1.17590098e-04  1.00000000e+00]\n",
      " [-1.14670423e-04  1.00000000e+00]\n",
      " [-1.09731503e-04  1.00000000e+00]\n",
      " [-9.88510074e-05  1.00000000e+00]\n",
      " [-7.01192621e-05  1.00000000e+00]\n",
      " [-6.95919880e-05  1.00000000e+00]\n",
      " [-4.54985966e-05  1.00000000e+00]\n",
      " [-1.93911856e-05  1.00000000e+00]\n",
      " [-2.28374574e-06  1.00000000e+00]\n",
      " [ 3.52586926e-06  1.00000000e+00]\n",
      " [ 8.32464502e-06  1.00000000e+00]\n",
      " [ 8.51559980e-06  1.00000000e+00]\n",
      " [ 8.62141042e-06  1.00000000e+00]\n",
      " [ 1.88359190e-05  1.00000000e+00]\n",
      " [ 2.44760067e-05  1.00000000e+00]\n",
      " [ 4.39456198e-05  1.00000000e+00]\n",
      " [ 6.30444265e-05  1.00000000e+00]\n",
      " [ 6.41912338e-05  1.00000000e+00]\n",
      " [ 7.13056870e-05  1.00000000e+00]\n",
      " [ 7.21333126e-05  1.00000000e+00]\n",
      " [ 9.59434474e-05  1.00000000e+00]\n",
      " [ 9.93132926e-05  1.00000000e+00]\n",
      " [ 1.01166763e-04  1.00000000e+00]\n",
      " [ 1.25196224e-04  1.00000000e+00]\n",
      " [ 1.30419896e-04  1.00000000e+00]\n",
      " [ 1.42721401e-04  1.00000000e+00]\n",
      " [ 1.64756464e-04  1.00000000e+00]\n",
      " [ 1.94806766e-04  1.00000000e+00]\n",
      " [ 2.06847704e-04  1.00000000e+00]\n",
      " [ 2.30613223e-04  1.00000000e+00]\n",
      " [ 2.42416383e-04  1.00000000e+00]\n",
      " [ 2.55566207e-04  1.00000000e+00]\n",
      " [ 2.69173703e-04  1.00000000e+00]\n",
      " [ 3.44807806e-04  1.00000000e+00]\n",
      " [ 4.03654616e-04  1.00000000e+00]]\n",
      "0.003\n",
      "[[-3.96103656e-04  1.00000000e+00]\n",
      " [-3.90365371e-04  1.00000000e+00]\n",
      " [-3.79911682e-04  1.00000000e+00]\n",
      " [-3.16131307e-04  1.00000000e+00]\n",
      " [-2.76657462e-04  1.00000000e+00]\n",
      " [-2.52481928e-04  1.00000000e+00]\n",
      " [-2.47451098e-04  1.00000000e+00]\n",
      " [-2.41628062e-04  1.00000000e+00]\n",
      " [-2.39980218e-04  1.00000000e+00]\n",
      " [-2.39935180e-04  1.00000000e+00]\n",
      " [-2.35203421e-04  1.00000000e+00]\n",
      " [-2.09757185e-04  1.00000000e+00]\n",
      " [-2.00712326e-04  1.00000000e+00]\n",
      " [-1.93419342e-04  1.00000000e+00]\n",
      " [-1.45603801e-04  1.00000000e+00]\n",
      " [-1.39421609e-04  1.00000000e+00]\n",
      " [-1.22671714e-04  1.00000000e+00]\n",
      " [-1.10016983e-04  1.00000000e+00]\n",
      " [-7.23199482e-05  1.00000000e+00]\n",
      " [-7.05990824e-05  1.00000000e+00]\n",
      " [-6.22705484e-05  1.00000000e+00]\n",
      " [-4.67822465e-05  1.00000000e+00]\n",
      " [-2.91770812e-05  1.00000000e+00]\n",
      " [-1.79606541e-05  1.00000000e+00]\n",
      " [-1.36444578e-05  1.00000000e+00]\n",
      " [-8.62513662e-06  1.00000000e+00]\n",
      " [-7.29954354e-06  1.00000000e+00]\n",
      " [ 5.77633955e-06  1.00000000e+00]\n",
      " [ 1.69179475e-05  1.00000000e+00]\n",
      " [ 3.18618149e-05  1.00000000e+00]\n",
      " [ 4.27164450e-05  1.00000000e+00]\n",
      " [ 6.40900835e-05  1.00000000e+00]\n",
      " [ 7.03059704e-05  1.00000000e+00]\n",
      " [ 7.46488804e-05  1.00000000e+00]\n",
      " [ 7.55144065e-05  1.00000000e+00]\n",
      " [ 9.95329465e-05  1.00000000e+00]\n",
      " [ 1.04658000e-04  1.00000000e+00]\n",
      " [ 1.28759508e-04  1.00000000e+00]\n",
      " [ 1.36303992e-04  1.00000000e+00]\n",
      " [ 1.36364019e-04  1.00000000e+00]\n",
      " [ 1.45605198e-04  1.00000000e+00]\n",
      " [ 2.06574216e-04  1.00000000e+00]\n",
      " [ 2.06586366e-04  1.00000000e+00]\n",
      " [ 2.50083889e-04  1.00000000e+00]\n",
      " [ 2.55810708e-04  1.00000000e+00]\n",
      " [ 2.55951425e-04  1.00000000e+00]\n",
      " [ 2.67275580e-04  1.00000000e+00]\n",
      " [ 2.74212012e-04  1.00000000e+00]\n",
      " [ 4.03245795e-04  1.00000000e+00]\n",
      " [ 4.33662382e-04  1.00000000e+00]]\n",
      "0.003\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2a23c1070d97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mniter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mniter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-e6f19dba10ff>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(sess, niter, ninitial, figdir)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrefsample_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdref_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdy_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdloss_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrefsample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtrain_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mgloss_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgtrain_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#print(np.shape(y_),np.shape(refsample_))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    s.close()\n",
    "except NameError:\n",
    "    pass\n",
    "s = tf.InteractiveSession()\n",
    "s.run(tf.global_variables_initializer())\n",
    "run_training(s,niter=FLAGS.niter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find more realistic values of kernel hyperparams\n",
    "# use ARD kernel\n",
    "# figure out how to train kernel\n",
    "# use datasets from titsias\n",
    "# experiment with number of pips\n",
    "# display distribution over clusters\n",
    "\n",
    "# From Ricardo:\n",
    "# smaller number of pseudo-inputs -- say 100-200\n",
    "# this number should be similar to the number of clusters\n",
    "# make sure pseudo-inputs aren't too similar\n",
    "# this could prevent kernel from collapsing\n",
    "\n",
    "# the ability to check pseudo-inputs for similarity: can't do it\n",
    "# hey, i'm going to select pseudo-inputs, and when I draw I only get 150 that are different, I only draw 150\n",
    "# in contrast, nothing you can do about this with previous way\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
