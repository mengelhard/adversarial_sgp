{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.contrib import slim\n",
    "from tensorflow.contrib import distributions\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import os\n",
    "\n",
    "from sgp_utils import nlog_fitc, nlog_vfe, fitc_pred, vfe_pred\n",
    "\n",
    "class FLAGS:\n",
    "    def __getattr__(self, name):\n",
    "        self.__dict__[name] = FLAGS()\n",
    "        return self.__dict__[name]\n",
    "\n",
    "FLAGS = FLAGS()\n",
    "\n",
    "FLAGS.img_path = './img'\n",
    "FLAGS.niter = 10000\n",
    "FLAGS.burn_in = 100\n",
    "FLAGS.print_freq = 500\n",
    "FLAGS.g_lr = 2e-5\n",
    "FLAGS.d_lr = 1e-4\n",
    "FLAGS.batch_size = 200\n",
    "FLAGS.gen_type = 1\n",
    "FLAGS.dataset = 'kin40k'\n",
    "FLAGS.val_prc = .2\n",
    "FLAGS.n_clusters = 100\n",
    "FLAGS.n_z = 300\n",
    "FLAGS.num_refs = 5\n",
    "FLAGS.num_sgp_samples = 20\n",
    "FLAGS.sgp_approx = 'vfe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kin40k(val_prc=0):\n",
    "    \n",
    "    import pandas as pd\n",
    "\n",
    "    kin40k_dir = '/Users/mme/Dropbox/_projects/gp_gan/data/kin40k/'\n",
    "\n",
    "    # Read KIN40K Data\n",
    "    train_x = pd.read_csv(kin40k_dir+'kin40k_train_data.asc',sep=' ',header=None,skipinitialspace=True).values\n",
    "    train_y = pd.read_csv(kin40k_dir+'kin40k_train_labels.asc',sep=' ',header=None,skipinitialspace=True).values\n",
    "    test_x = pd.read_csv(kin40k_dir+'kin40k_test_data.asc',sep=' ',header=None,skipinitialspace=True).values\n",
    "    test_y = pd.read_csv(kin40k_dir+'kin40k_test_labels.asc',sep=' ',header=None,skipinitialspace=True).values\n",
    "    train_y = np.squeeze(train_y)\n",
    "    test_y = np.squeeze(test_y)\n",
    "\n",
    "    # Normalize KIN40K Data\n",
    "\n",
    "    x_var = np.var(train_x,axis=0)\n",
    "    x_mean = np.mean(train_x,axis=0)\n",
    "    y_var = np.var(train_y)\n",
    "    y_mean = np.mean(train_y)\n",
    "\n",
    "    train_x = (train_x-x_mean)/x_var\n",
    "    test_x = (test_x-x_mean)/x_var\n",
    "    train_y = (train_y-y_mean)/y_var\n",
    "    test_y = (test_y-y_mean)/y_var\n",
    "\n",
    "    # Create a validation set (20% of training data)\n",
    "\n",
    "    val_indices = np.random.permutation(np.arange(len(train_x)))<int(val_prc*len(train_x))\n",
    "    val_x = train_x[val_indices,:]\n",
    "    val_y = train_y[val_indices]\n",
    "    train_x = train_x[~val_indices,:]\n",
    "    train_y = train_y[~val_indices]\n",
    "\n",
    "    return train_x, train_y, val_x, val_y, test_x, test_y\n",
    "\n",
    "def load_otherdata():\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_mixture_model(d,n_clusters=100,random_state=0):\n",
    "    \"\"\"\n",
    "    Cluster x and return cluster centers and cluster widths (variances)\n",
    "    \"\"\"\n",
    "    from sklearn.cluster import MiniBatchKMeans\n",
    "    km = MiniBatchKMeans(n_clusters=n_clusters,random_state=random_state).fit(d)\n",
    "\n",
    "    lbls = km.labels_\n",
    "    cc = km.cluster_centers_\n",
    "\n",
    "    d_centered = np.array([x - cc[y] for x,y in zip(d,lbls)])\n",
    "    c_widths = np.array([np.sum(d_centered[lbls==c,:]**2,axis=0)/np.sum(lbls==c) \n",
    "        for c in range(n_clusters)])\n",
    "\n",
    "    weights = np.array([np.sum(lbls==c) for c in range(n_clusters)])\n",
    "    weights = weights/np.sum(weights)\n",
    "\n",
    "    mixture_model = {\n",
    "        'n_components':n_clusters,\n",
    "        'n_dims':np.shape(d)[1],\n",
    "        'weights':weights,\n",
    "        'means':cc,\n",
    "        'sds':np.sqrt(c_widths)\n",
    "        }\n",
    "\n",
    "    return mixture_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logdet(matrix):\n",
    "    chol = tf.cholesky(matrix)\n",
    "    return 2.0 * tf.reduce_sum(tf.log(tf.real(tf.matrix_diag_part(chol))),reduction_indices=[-1])\n",
    "\n",
    "def pairwise_distance(x1,x2):\n",
    "    r1 = tf.reduce_sum(x1**2,axis=2)[:,:,tf.newaxis]\n",
    "    r2 = tf.reduce_sum(x2**2,axis=2)[:,tf.newaxis,:]\n",
    "    r12 = tf.matmul(x1,tf.matrix_transpose(x2))\n",
    "    return r1+r2-2*r12\n",
    "\n",
    "def nlog_vfe(x,y,m,sls,sfs,noise):\n",
    "\n",
    "    P = tf.shape(m)[0] # number of pseudo-input samples\n",
    "    y = tf.tile(tf.expand_dims(tf.cast(y,dtype=tf.float32),0),(P,1))\n",
    "    x = tf.tile(tf.expand_dims(tf.cast(x,dtype=tf.float32),0),(P,1,1))\n",
    "\n",
    "    D = tf.shape(x)[2]\n",
    "    X = tf.shape(x)[1]\n",
    "\n",
    "    logtp = tf.constant(np.log(2.*np.pi),dtype=tf.float32)\n",
    "\n",
    "    #m = m + 1e-6*tf.random_normal(tf.shape(m),dtype=tf.float32)\n",
    "\n",
    "    M = tf.shape(m)[1]\n",
    "\n",
    "    jitter = 1e-6*tf.eye(M,dtype=tf.float32)[tf.newaxis,:,:]\n",
    "\n",
    "    xm = pairwise_distance(x,m)\n",
    "    mm = pairwise_distance(m,m)\n",
    "\n",
    "    kxm = sfs[:,tf.newaxis,tf.newaxis]*tf.exp(-.5*xm/sls[:,tf.newaxis,tf.newaxis])\n",
    "    kmm = sfs[:,tf.newaxis,tf.newaxis]*tf.exp(-.5*mm/sls[:,tf.newaxis,tf.newaxis])\n",
    "    \n",
    "    kmx = tf.matrix_transpose(kxm)\n",
    "    kmmi = tf.matrix_inverse(kmm+jitter)\n",
    "\n",
    "    qmm_diag = tf.reduce_sum(tf.matmul(kxm,kmmi)*kxm,axis=2)\n",
    "    \n",
    "    gd = noise[:,tf.newaxis]\n",
    "    gid = 1/gd\n",
    "\n",
    "    tr = sfs*tf.cast(X,tf.float32)-tf.reduce_sum(qmm_diag,axis=1)\n",
    "    \n",
    "    kmx_gi_kxm = tf.matmul(kmx,kxm)/noise[:,tf.newaxis,tf.newaxis]\n",
    "\n",
    "    giy = gid*y\n",
    "    kgiy = tf.reduce_sum(kmx*giy[:,tf.newaxis,:],axis=2)\n",
    "\n",
    "    inner = kmmi+kmx_gi_kxm+jitter\n",
    "\n",
    "    covd = logdet(inner)+logdet(kmm+jitter)+tf.log(noise)*tf.cast(X,dtype=tf.float32)\n",
    "    \n",
    "    t1 = .5*tf.cast(X,tf.float32)*logtp\n",
    "    t2 = .5*tf.reduce_sum(y*y*gid,axis=1) - .5*tf.reduce_sum(\n",
    "        tf.reduce_sum(kgiy[:,:,tf.newaxis]*tf.matrix_inverse(inner),axis=1)*kgiy,axis=1)\n",
    "    t3 = .5*covd\n",
    "    t4 = .5*tf.div(tr,noise)\n",
    "    \n",
    "    return t1+t2+t3+t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to make and evaluate predictions\n",
    "\n",
    "#def get_mse(pred,real):\n",
    "#    se = (pred-real)**2\n",
    "#    ms = np.mean(se)\n",
    "#    return ms, ms/np.var(real)\n",
    "\n",
    "def get_mse(pred,real): # check axes\n",
    "    se = (pred-real)**2\n",
    "    ms = tf.reduce_mean(se)\n",
    "    _, var = tf.nn.moments(real, axes=[0])\n",
    "    return ms, ms/var\n",
    "\n",
    "def vfe_pred(x,y,t,m,sls,sfs,noise):\n",
    "    \n",
    "    P = tf.shape(m)[0] # number of pseudo-input samples\n",
    "    y = tf.tile(tf.expand_dims(tf.cast(y,dtype=tf.float32),0),(P,1))\n",
    "    x = tf.tile(tf.expand_dims(tf.cast(x,dtype=tf.float32),0),(P,1,1))\n",
    "    t = tf.tile(tf.expand_dims(tf.cast(t,dtype=tf.float32),0),(P,1,1))\n",
    "\n",
    "    D = tf.shape(x)[2]\n",
    "    X = tf.shape(x)[1]\n",
    "\n",
    "    logtp = tf.constant(np.log(2.*np.pi),dtype=tf.float32)\n",
    "\n",
    "    M = tf.shape(m)[1]\n",
    "\n",
    "    jitter = 1e-6*tf.eye(M,dtype=tf.float32)[tf.newaxis,:,:]\n",
    "\n",
    "    xm = pairwise_distance(x,m)\n",
    "    mm = pairwise_distance(m,m)\n",
    "\n",
    "    kxm = sfs[:,tf.newaxis,tf.newaxis]*tf.exp(-.5*xm/sls[:,tf.newaxis,tf.newaxis])\n",
    "    kmm = sfs[:,tf.newaxis,tf.newaxis]*tf.exp(-.5*mm/sls[:,tf.newaxis,tf.newaxis])\n",
    "    kmx = tf.matrix_transpose(kxm)\n",
    "\n",
    "    tm = pairwise_distance(t,m)\n",
    "\n",
    "    ktm = sfs[:,tf.newaxis,tf.newaxis]*tf.exp(-.5*tm/sls[:,tf.newaxis,tf.newaxis])\n",
    "\n",
    "    giy = y/noise[:,tf.newaxis]\n",
    "    kgiy = tf.reduce_sum(kmx*giy[:,tf.newaxis,:],axis=2)\n",
    "    kmx_gi_kxm = tf.matmul(kmx,kxm)/noise[:,tf.newaxis,tf.newaxis]\n",
    "    qm = kmm+kmx_gi_kxm+jitter\n",
    "\n",
    "    ph = tf.reduce_sum(tf.matrix_inverse(qm)*kgiy[:,tf.newaxis,:],axis=2)\n",
    "    mean = tf.reduce_sum(ktm*ph[:,tf.newaxis,:],axis=2)\n",
    "\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### MAIN ###\n",
    "\n",
    "# Load data\n",
    "\n",
    "if FLAGS.dataset == 'kin40k':\n",
    "    train_x, train_y, val_x, val_y, test_x, test_y = load_kin40k(val_prc=FLAGS.val_prc)\n",
    "\n",
    "# PSEUDOCODE HERE FOR THE MOMENT\n",
    "\n",
    "initial_model = kmeans_mixture_model(train_x,n_clusters=FLAGS.n_clusters)\n",
    "\n",
    "sls = tf.expand_dims(tf.Variable(1.,name='sls',dtype=tf.float32),axis=0)\n",
    "sfs = tf.expand_dims(tf.Variable(1.,name='sfs',dtype=tf.float32),axis=0)\n",
    "noise = tf.expand_dims(tf.Variable(1e-3,name='noise',dtype=tf.float32),axis=0)\n",
    "\n",
    "z = tf.expand_dims(tf.Variable(initial_model['means'],name='z',dtype=tf.float32),axis=0)\n",
    "\n",
    "# Get SGP stuff\n",
    "sgp_nlogprob = nlog_vfe(train_x,train_y,z,sls,sfs,noise)\n",
    "   \n",
    "train_step = tf.train.AdamOptimizer(1e-1).minimize(sgp_nlogprob)\n",
    "\n",
    "pred = vfe_pred(train_x,train_y,test_x,z,sls,sfs,noise)\n",
    "mse, nmse = get_mse(tf.squeeze(pred),tf.constant(test_y,dtype=tf.float32))\n",
    "\n",
    "# Get MSE / normalized MSE\n",
    "\n",
    "outdir = FLAGS.img_path\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(sess, niter=FLAGS.niter, printfreq=100):\n",
    "\n",
    "    progress = tqdm_notebook(range(niter))\n",
    "    error = []\n",
    "\n",
    "    for i in progress:\n",
    "\n",
    "        sgp_nlogprob_,sls_,sfs_,noise_,_,nmse_ = sess.run([sgp_nlogprob,sls,sfs,noise,train_step,nmse])\n",
    "\n",
    "        #print(np.shape(y_),np.shape(refsample_))\n",
    "\n",
    "        progress.set_description(\"nlp=%.0f,l=%.3f,s=%.3f,n=%.3f\"  % (sgp_nlogprob_,sls_,sfs_,noise_))\n",
    "        \n",
    "        error.append(nmse_)\n",
    "        \n",
    "        if i%printfreq == (printfreq-1):\n",
    "            print('normalized MSE is %.3f' % nmse_)\n",
    "        \n",
    "    # if it's time, check the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593693fc7e584640984a1726adc1c633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized MSE is 0.323\n",
      "normalized MSE is 0.301\n",
      "normalized MSE is 0.288\n",
      "normalized MSE is 0.282\n",
      "normalized MSE is 0.274\n",
      "normalized MSE is 0.264\n",
      "normalized MSE is 0.257\n",
      "normalized MSE is 0.253\n",
      "normalized MSE is 0.248\n",
      "normalized MSE is 0.242\n",
      "normalized MSE is 0.239\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-2a23c1070d97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mniter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mniter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-48ebeb6a63c1>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(sess, niter, printfreq)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0msgp_nlogprob_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msls_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msfs_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnoise_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnmse_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msgp_nlogprob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msfs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnmse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m#print(np.shape(y_),np.shape(refsample_))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    s.close()\n",
    "except NameError:\n",
    "    pass\n",
    "s = tf.InteractiveSession()\n",
    "s.run(tf.global_variables_initializer())\n",
    "run_training(s,niter=FLAGS.niter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
